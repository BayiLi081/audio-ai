{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d18653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d830914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the file and parse it\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# Replace with your actual file path\n",
    "file_path = 'outputs/txts/staffmeeting/staffmeeting_transcribed.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    raw_lines = f.readlines()\n",
    "\n",
    "# Extract all spoken text\n",
    "all_texts = []\n",
    "\n",
    "for line in raw_lines:\n",
    "    match = re.search(r'Text:\\s*(.*)', line)\n",
    "    if match:\n",
    "        all_texts.append(match.group(1).strip())\n",
    "\n",
    "full_meeting_transcript = ' '.join(all_texts)\n",
    "\n",
    "# Step 2: Extract speaker segments and group by speaker\n",
    "speaker_texts = defaultdict(list)\n",
    "\n",
    "for line in raw_lines:\n",
    "    match = re.search(r'Speaker:\\s*(SPEAKER_\\d+).*?Text:\\s*(.*)', line)\n",
    "    if match:\n",
    "        speaker = match.group(1)\n",
    "        text = match.group(2).strip()\n",
    "        speaker_texts[speaker].append(text)\n",
    "\n",
    "# Step 3: Combine each speaker's full speech into one string\n",
    "combined_speeches = {\n",
    "    speaker: ' '.join(texts)\n",
    "    for speaker, texts in speaker_texts.items()\n",
    "}\n",
    "\n",
    "# # remove 'SPEAKER_5' because they only have one line\n",
    "# del combined_speeches['SPEAKER_05']\n",
    "\n",
    "combined_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f001dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define function to query your local Ollama LLM (DeepSeek-R1:14B)\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "def query_ollama(prompt, model=\"deepseek-r1:14b\"):\n",
    "    command = ['ollama', 'run', model]\n",
    "    process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    stdout, stderr = process.communicate(input=prompt)\n",
    "    return stdout.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546aed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate summary for each speaker\n",
    "summaries = {}\n",
    "\n",
    "for speaker, speech in combined_speeches.items():\n",
    "    prompt = f\"Summarise the key ideas expressed by {speaker} in the following transcript:\\n\\n{speech}\\n\\nKeep it concise and focus on the main points.\"\n",
    "    print(f\"Summarising {speaker}...\")\n",
    "    summary = query_ollama(prompt)\n",
    "    summaries[speaker] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7205ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.DataFrame.from_dict(summaries, orient='index', columns=['Summary']).reset_index()\n",
    "summaries.rename(columns={'index': 'Speaker'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d75aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the 'Summary' column into two columns: 'Summary' and 'Speaker' divided by \"</think>\"\n",
    "summaries['thinking'] = summaries['Summary'].apply(lambda x: x.split('</think>')[0].strip())\n",
    "summaries['Summary'] = summaries['Summary'].apply(lambda x: x.split('</think>')[1].strip() if '</think>' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['thinking'] = summaries['thinking'].apply(lambda x: x.replace('<think>\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb4eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries.to_csv('outputs/summaries_30_july.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create prompt and run the summary\n",
    "prompt = (\n",
    "    \"You are a helpful assistant. Summarise the following meeting transcript into a clear, concise summary. \"\n",
    "    \"Focus on the main ideas discussed, decisions made, and any concerns or tensions raised.\\n\\n\"\n",
    "    f\"{full_meeting_transcript}\"\n",
    ")\n",
    "\n",
    "summary = query_ollama(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_text = summary.split('</think>')[1].strip()\n",
    "\n",
    "print(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551ff9b",
   "metadata": {},
   "source": [
    "Get the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.read_csv('outputs/summaries_30_july.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
