{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e4479e",
   "metadata": {},
   "source": [
    "the python environment will be audio-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pyannote.audio import Pipeline\n",
    "import os\n",
    "import torch\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from load_pipeline import load_pipeline_from_pretrained\n",
    "\n",
    "from to_wav import convert_to_wav\n",
    "\n",
    "from transcribe_segments import transcribe_speaker_segments\n",
    "\n",
    "PATH_TO_CONFIG = \"models/pyannote_diarization_config.yaml\"\n",
    "pipeline = load_pipeline_from_pretrained(PATH_TO_CONFIG)\n",
    "\n",
    "if pipeline is not None:\n",
    "    pipeline.to(torch.device(\"cuda\"))\n",
    "else:\n",
    "    print(\"Failed to load the pipeline. Please check your Hugging Face token and model access.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d1516",
   "metadata": {},
   "source": [
    "supports a wide range of audio file formats, including MP3, WAV, AAC, FLAC, OGG, and more. You can specify the format when importing audio and export audio to different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./test_audio/\"\n",
    "audio_name = \"UTokyo_29Sep\"\n",
    "input_format = 'm4a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d54999",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_output_dir = Path(f'outputs/txts/{audio_name}')\n",
    "summary_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "input_path = audio_path + audio_name + \".\" + input_format\n",
    "convert_to_wav(input_path, input_format, output_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pretrained pipeline\n",
    "diarization = pipeline(audio_path + audio_name + \".wav\")\n",
    "\n",
    "rows = []\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    rows.append({\n",
    "        \"speaker\": speaker,\n",
    "        \"duration\": turn.end - turn.start,\n",
    "        \"start\": turn.start,\n",
    "        \"end\": turn.end\n",
    "    })\n",
    "\n",
    "speaker_durations = pd.DataFrame(rows, columns=[\"speaker\", \"duration\", \"start\", \"end\"])\n",
    "\n",
    "# uncomment the following line to when the speaker start to talk and end\n",
    "# for index, row in speaker_durations.iterrows():\n",
    "#     print(f\"Speaker {row['speaker']} spoke for {row['duration']:.1f} seconds.\")\n",
    "\n",
    "# remove the duration that is less than 3 seconds\n",
    "speaker_durations = speaker_durations[speaker_durations['duration'] >= 3]\n",
    "\n",
    "speaker_durations.reset_index(drop=True, inplace=True)\n",
    "# add a unique id for each segment\n",
    "speaker_durations['seg_unique_id'] = speaker_durations.index\n",
    "\n",
    "speaker_durations['speaker'].value_counts().plot(kind='bar', title='Speaker Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ed55d",
   "metadata": {},
   "source": [
    "Use the OpenAI Whisper Model to transcribe the audio to txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_durations = transcribe_speaker_segments(\n",
    "    speaker_durations = speaker_durations,\n",
    "    audio_wav_path = audio_path + audio_name + \".wav\",\n",
    "    output_dir = f\"./outputs/segments/{audio_name}/\",\n",
    "    output_csv_path = f\"./outputs/csv/{audio_name}/speaking_durations.csv\",\n",
    "    model_name = \"small.en\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd89a19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This part is another part you need to manully input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_dic = {\n",
    "    \"SPEAKER_00\": \"real_name_1\",\n",
    "    \"SPEAKER_01\": \"real_name_2\",\n",
    "    \"SPEAKER_02\": \"real_name_3\",\n",
    "}\n",
    "\n",
    "speaker_durations['speaker'] = speaker_durations['speaker'].replace(speakers_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the speaker_durations to a txt file \n",
    "with open(summary_output_dir / f\"{audio_name}_transcribed.txt\", \"w\") as f:\n",
    "    for index, row in speaker_durations.iterrows():\n",
    "        f.write(f\"Segment ID: {row['seg_unique_id']}, Speaker: {row['speaker']}, Start: {row['start']}, End: {row['end']}, Text: {row['text']}\\n\")\n",
    "\n",
    "for speaker in speaker_durations['speaker'].unique():\n",
    "    speaker_segments = speaker_durations[speaker_durations['speaker'] == speaker]\n",
    "    with open(summary_output_dir / f\"{audio_name}_speaker_{speaker}.txt\", \"w\") as f:\n",
    "        for index, row in speaker_segments.iterrows():\n",
    "            f.write(f\"{row['text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6fd436",
   "metadata": {},
   "source": [
    "Go to [cleantxt.ipynb](./cleantxt.ipynb) to further clean the generated txt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
